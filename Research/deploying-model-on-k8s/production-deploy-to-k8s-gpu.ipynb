{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/production-deploy-to-aks-gpu/production-deploy-to-aks-gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a ML model as web service on Kubernetes\n",
    "This notebook shows the steps to : registering a model, creating an image, creating Kubernetes Deployment for a service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1601051195792
    }
   },
   "outputs": [],
   "source": [
    "#upgrade to latest versionof sdk \n",
    "!pip install --upgrade azureml-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599847277289
    }
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get workspace\n",
    "Please create a azure Machine learnign workspace on portal.azure.com before runing this notebook, once created download config.json from your workspace,  please place config.json file from portal to same folder as notebook ![Capture_withoverlay.JPG](pics/conf_file_download.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599847578183
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config(path=\"ml_workspace_config.json\")\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the model\n",
    "\n",
    "Prior to registering the model, you should have a TensorFlow [Saved Model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md) in the `resnet50` directory. This cell will download a [pretrained resnet50](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW_jpg.tar.gz) and unpack it to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599847838909
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW_jpg.tar.gz\"\n",
    "\n",
    "archive_prefix = \"./resnet_v1_fp32_savedmodel_NCHW_jpg/1538686758/\"\n",
    "target_folder = \"resnet50\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    print(f\"target_folder \\\"{target_folder}\\\" does not exist.\")\n",
    "    print(f\"Downloading it from \\\"{model_url}\\\"...\")\n",
    "    response = requests.get(model_url)\n",
    "    archive = tarfile.open(fileobj=BytesIO(response.content))\n",
    "    with tempfile.TemporaryDirectory() as temp_folder:\n",
    "        print(f\"extracting in \\\"{temp_folder}\\\"...\")\n",
    "        archive.extractall(temp_folder)\n",
    "        print(f\"copyint to \\\"{target_folder}\\\"...\")\n",
    "        shutil.copytree(os.path.join(temp_folder, archive_prefix), target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the model\n",
    "Register an existing trained model, add description and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599847916495
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path=\"resnet50\", # This points to the local directory to upload.\n",
    "                       model_name=\"resnet50\", # This is the name the model is registered as.\n",
    "                       tags={'area': \"Image classification\", 'type': \"classification\"},\n",
    "                       description=\"Image classification trained on Imagenet Dataset\",\n",
    "                       workspace=ws)\n",
    "\n",
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model as a web service\n",
    "\n",
    "We begin by writing a score.py file that will be invoked by the web service call. The init() function is called once when the container is started so we load the model using the Tensorflow session. The run() function is called when the webservice is invoked for inferencing. After running the code below you should see a score.py file in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from azureml.contrib.services.aml_request import AMLRequest, rawhttp\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "\n",
    "def init():\n",
    "    global session\n",
    "    global input_name\n",
    "    global output_name\n",
    "    \n",
    "    print(f\"getting tf.Session()...\")\n",
    "    session = tf.Session()\n",
    "    print(f\"got tf.Session()\")\n",
    "    \n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'resnet50')\n",
    "    print(f\"model_path: \\\"{model_path}\\\"\")\n",
    "    \n",
    "    model = tf.saved_model.loader.load(session, ['serve'], model_path)\n",
    "    if len(model.signature_def['serving_default'].inputs) > 1:\n",
    "        raise ValueError(\"This score.py only supports one input\")\n",
    "    input_name = [tensor.name for tensor in model.signature_def['serving_default'].inputs.values()][0]\n",
    "    output_name = [tensor.name for tensor in model.signature_def['serving_default'].outputs.values()]\n",
    "    \n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "    if request.method == 'POST':\n",
    "        reqBody = request.get_data(False)\n",
    "        resp = score(reqBody)\n",
    "        return AMLResponse(resp, 200)\n",
    "    if request.method == 'GET':\n",
    "        respBody = str.encode(\"GET is not supported\")\n",
    "        return AMLResponse(respBody, 405)\n",
    "    return AMLResponse(\"bad request\", 500)\n",
    "\n",
    "def score(data):\n",
    "    print(f\"doing score()...\")\n",
    "    result = session.run(output_name, {input_name: [data]})\n",
    "    return json.dumps(result[1].tolist())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    with open(\"test_image.jpg\", 'rb') as f:\n",
    "        content = f.read()\n",
    "        print(score(content))\n",
    "    print(f\"done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the deployment configuration objects. We mention `score.py`, which we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599848048510
    }
   },
   "outputs": [],
   "source": [
    "# Set the web service configuration (using default here)\n",
    "from azureml.core.model import InferenceConfig\n",
    "#from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment, DEFAULT_GPU_IMAGE\n",
    "\n",
    "env = Environment('deploytoedgeenv')\n",
    "# Please see [Azure ML Containers repository](https://github.com/Azure/AzureML-Containers#featured-tags)\n",
    "# for open-sourced GPU base images.\n",
    "env.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['tensorflow-gpu==1.12.0','numpy'],\n",
    "                                 pip_packages=['azureml-contrib-services', 'azureml-defaults'])\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create container image in Azure ML\n",
    "Use Azure ML to create the container image. This step will likely take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599849666607
    }
   },
   "outputs": [],
   "source": [
    "# provide name of azure contaienr image and tag \n",
    "imagename= \"tfgpu\"\n",
    "imagelabel=\"1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599849926532
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Builds an image in ACR.\n",
    "\n",
    "package = Model.package(ws, [model], inference_config=inference_config,image_name=imagename, image_label=imagelabel)\n",
    "package.wait_for_creation(show_output=True)\n",
    "\n",
    "print(\"ACR:\", package.get_container_registry)\n",
    "print(\"Image:\", package.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy container to Azure Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "acr_name = package.location.split(\"/\")[0]\n",
    "reg_name = acr_name.split(\".\")[0]\n",
    "subscription_id = ws.subscription_id\n",
    "\n",
    "print('acr_name: {}'.format(acr_name))\n",
    "print('subscription_id: {}'.format(subscription_id))\n",
    "\n",
    "# TODO: Derive image_location through code.\n",
    "image_location = acr_name + \"/\" + imagename + \":\" + imagelabel\n",
    "\n",
    "print('image_location: {}'.format(image_location))\n",
    "\n",
    "# Fetch username, password of ACR.\n",
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "from azure.mgmt import containerregistry\n",
    "\n",
    "client = ContainerRegistryManagementClient(ws._auth,subscription_id)\n",
    "result= client.registries.list_credentials(ws.resource_group, reg_name, custom_headers=None, raw=False)\n",
    "\n",
    "username = result.username\n",
    "password = result.passwords[0].value\n",
    "\n",
    "# Do not commit your credentials to this notebook's source repository.\n",
    "# print(\"using username \\\"\" + username + \"\\\"\")\n",
    "# print(\"using password \\\"\" + password + \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Kubernetes Deployment faile\n",
    "\n",
    "Below is the template for our Kubernetes deployments. We create it within this notebook for visibility, for more complex deployments you can make it part of source control repository.\n",
    "\n",
    "We will apply `image_location` that we composed to __REGISTRY_IMAGE_LOCATION.\n",
    "\n",
    "The value for the new marco-definition, __REGISTRY_SECRET_NAME, is the result of the authentication process you need to do to be able to connect to a private container registry(docker image repository)\n",
    "\n",
    "We will do steps described in https://github.com/Azure-Samples/azure-intelligent-edge-patterns/tree/master/Research/deploying-model-on-k8s , and you are welcome to familiarize yourself with the subject at https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n",
    "\n",
    "At the Kubernetes cluster where you want this image to be available, you will need to login to your ACR, you can use the value `image_location` we have in this notebook:\n",
    "\n",
    "```\n",
    "$ docker login <your account it>.azurecr.io\n",
    "Username: <your user id>\n",
    "Password:\n",
    "Login Succeeded\n",
    "```\n",
    "\n",
    "This will record the authentication token in your ~/.docker/config.json, and you will be able to create a Kubernetes secret to use to access your private repository.\n",
    "\n",
    "You need to be able to use `kubectl`, and your `kubectl` should be able to access the cluster. Cluster is usually defined by a `kubeconfig` file, which contains the authentication tokens, usually located in `~/.kube/config` on the master node of your Kubernetes cluster. You need to copy its content to the machine where you installed kubectl.\n",
    "\n",
    "Here is how you can check your kubectl is working:\n",
    "\n",
    "```\n",
    "$ kubectl version\n",
    "Client Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.6-beta.0\", GitCommit:\"e7f962ba86f4ce7033828210ca3556393c377bcc\", GitTreeState:\"clean\", BuildDate:\"2020-01-15T08:26:26Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"windows/amd64\"}\n",
    "Server Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.6-beta.0\", GitCommit:\"e7f962ba86f4ce7033828210ca3556393c377bcc\", GitTreeState:\"clean\", BuildDate:\"2020-01-15T08:18:29Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
    "```\n",
    "\n",
    "And here is how you can look at your Kubernetes cluster nodes (once you copied your kubeconfig file):\n",
    "\n",
    "```\n",
    "$ kubectl get nodes\n",
    "NAME             STATUS   ROLES    AGE    VERSION\n",
    "docker-desktop   Ready    master   120d   v1.16.6-beta.0\n",
    "```\n",
    "\n",
    "Now you can create your private registry access secret, we will call it `secret4acr2infer`:\n",
    "\n",
    "```\n",
    "$ kubectl create secret generic secret4acr2infer \\\n",
    "    --from-file=.dockerconfigjson=~/.docker/config.json \\\n",
    "    --type=kubernetes.io/dockerconfigjson\n",
    "```    \n",
    "    \n",
    "For more information, please see [Pull an Image from a Private Registry](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deployment-k8s-template-gpu.yaml\n",
    "#\n",
    "# You can deploy this Deployment like so:\n",
    "#\n",
    "# $ kubectl create -f deployment-k8s-gpu.yaml\n",
    "#\n",
    "# \n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: my-infer\n",
    "  labels:\n",
    "    app: my-infer\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: my-infer\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: my-infer\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: my-infer\n",
    "        image: __REGISTRY_IMAGE_LOCATION\n",
    "        ports:\n",
    "        # we use only 5001, but the container exposes  EXPOSE 5001 8883 8888\n",
    "        - containerPort: 5001\n",
    "        - containerPort: 8883\n",
    "        - containerPort: 8888\n",
    "        resources:\n",
    "          limits:\n",
    "            # if you know your models minimal requirements, you can control\n",
    "            # the resource usage here. Some models may not work unless they\n",
    "            # have enough.\n",
    "            #\n",
    "            # memory: \"128Mi\" #128 MB\n",
    "            # cpu: \"200m\" # 200 millicpu (0.2 or 20% of the cpu)\n",
    "            nvidia.com/gpu:  1\n",
    "      imagePullSecrets:\n",
    "        - name: __REGISTRY_SECRET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a deployment_gpu.yaml file using the template and the settings earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('deployment-k8s-template-gpu.yaml')\n",
    "\n",
    "contents = file.read()\n",
    "contents = contents.replace('__REGISTRY_IMAGE_LOCATION', image_location)\n",
    "contents = contents.replace('__REGISTRY_SECRET_NAME', \"secret4acr2infer\")\n",
    "\n",
    "with open('./deployment_gpu.yaml', 'wt', encoding='utf-8') as output_file:\n",
    "    output_file.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying .yaml to your Kubernetes cluster\n",
    "Then copy your deployment.yaml to the control box of your Kubernetes cluster(using `scp` or any ftp utility you like).\n",
    "\n",
    "At that machine, you apply the deployment to your cluster, and expose the service like so:\n",
    "    \n",
    "```    \n",
    "    $ kubectl create -f deployment_gpu.yaml\n",
    "    $ kubectl expose deployment my-infer --type=LoadBalancer --name=my-service-infer\n",
    "    $ kubectl get services\n",
    "    NAME               TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                                        AGE\n",
    "    kubernetes         ClusterIP      10.152.183.1    <none>        443/TCP                                        7d19h\n",
    "    my-service-infer   LoadBalancer   10.152.183.61   <your ip>     5001:30056/TCP,8883:31448/TCP,8888:31236/TCP   4h28m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the web service\n",
    "We test the web sevice by passing the test images content.\n",
    "\n",
    "If you are using your Cluster-IP, you need to be at that cluster. SSH to your master node, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading labels for imagenet that resnet model was trained on \n",
    "import requests\n",
    "classes_entries = requests.get(\"https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\").text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import requests\n",
    "\n",
    "test_sample = open('snowleopardgaze.jpg', 'rb').read()\n",
    "\n",
    "try:\n",
    "    #eg http://51.141.178.47:5001/score\n",
    "    scoring_uri = 'http://<replace with yout edge device ip address>:5001/score'\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request\n",
    "    resp = requests.post(scoring_uri, test_sample, headers=headers)  \n",
    "    \n",
    "    print(\"Found a ::\" + classes_entries[int(resp.text.strip(\"[]\")) - 1] )\n",
    "except KeyError as e:\n",
    "    print(str(e))"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "vaidyas"
   }
  ],
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
